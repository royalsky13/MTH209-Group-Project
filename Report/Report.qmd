---
title: "Genetic Correspondence and Comparative Spatial Analysis with Age and Gender Specification of ICMR Data on Cancer Incidence in India"
author:
  - name: Sarbojit Das (231080075)
    affil-id: "*"
  - name: Swapnonil Mondal (231080098)
    affil-id: "*"
  - name: Sameer Verma (220949)
    affil-id: "*"
  - name: Sujash Krishna Basak (231080093)
    affil-id: "*"
  - name: Sayanta Biswas (231080080)
    affil-id: "*"
affiliations:
  - id: "*"
    name: Department of Mathematics & Statistics, Indian Institute of Technology Kanpur, India
date: today
date-format: long
format: 
  pdf:
    number-sections: true
    number-depth: 3
    keep-tex: true
    documentclass: article
    template-partials: 
    - "template/title.tex"
    include-in-header:
      text: |
        \usepackage[noblocks]{authblk}
        \renewcommand*{\Authsep}{, }
        \renewcommand*{\Authand}{, }
        \renewcommand*{\Authands}{, }
        \renewcommand\Affilfont{\small}
execute: 
  cache: true
editor: visual
geometry: margin=1in
header-includes:
   - \usepackage{amsmath, amssymb, setspace}
   - \onehalfspacing
   - \usepackage{etoolbox} 
   - \makeatletter 
   - \preto{\@verbatim}{\topsep=3pt \partopsep=3pt } 
   - \makeatother
---

```{r}
#| label: load-packages
#| message: false
#| include: false
library(tibble)
library(rvest)
library(dplyr)
library(tidyverse)
library(ggplot2)
library(stats)
library(gplots)
library(knitr)
```

```{r}
#| message: false
#| include: false
load("ICMR.Rdata")
```

```{=tex}
\rule{\textwidth}{0.5 pt}
\begin{abstract}
Cancer remains a significant global health challenge, characterized by immense suffering and often limited treatment options. We aim to analyze genetic data related to five common cancer types, each presenting unique challenges and implications for diagnosis and treatment. Our goal is to identify the probable genetic causes underlying these cancers, providing leads for early identification and reducing fatality rates. Focusing on India, we explore the spatial and genetic aspects of cancer, utilizing statistical concepts and analyzing data from specific years. We aim to shed light on cancer prevalence, distribution and genetic underpinnings within the Indian population. Additionally, we investigate gender-specific and age-specific cancer incidence to offer detailed insights into the cancer landscape in India.
\end{abstract}
\rule{\textwidth}{0.5 pt}
```
## Introduction

Cancer is a formidable adversary to human health. It persists as a significant global burden, causing immeasurable suffering and presenting substantial challenges to healthcare systems worldwide. Its insidious nature lies in the uncontrolled growth and dissemination of abnormal cells, disrupting the delicate balance of cellular regulation inherent in the human body's natural processes. Despite remarkable advancements in medical science, the complexities of cancer remain a formidable challenge, often accompanied by limited treatment options and devastating outcomes for affected individuals and their families.

This project endeavors to delve into the multifaceted realm of cancer. With a diverse population and a unique set of demographic, environmental and genetic factors, India provides a rich tapestry for exploring the spatial, genetic, gender-specific and age-specific dimensions of cancer prevalence and distribution. Furthermore, our study extends beyond genetic analyses to explore the spatial aspects of cancer incidence in India. Leveraging statistical concepts and data from specific years, we seek to illuminate patterns of cancer prevalence and distribution across different regions of the country. This spatial perspective is crucial for understanding the geographic disparities in cancer burden and for informing targeted interventions and resource allocation efforts. Such insights hold the potential to inform tailored prevention, screening and treatment strategies, thereby improving outcomes and mitigating the impact of cancer on individuals and society at large.

Through this comprehensive exploration of cancer incidence in India, our project aims to contribute to a deeper understanding of the disease landscape. By integrating these aspects, we endeavor to shed light on the complexities of cancer and to ultimately strive towards a future where the burden of cancer is significantly reduced.

## Dataset

In this project, we deal with multiple datasets that are based on cancer patients and the nature of cancer in both male and female human bodies.

[**1. Cancer causing genes dataset:**](https://www.kaggle.com/datasets/shibumohapatra/icmr-data?select=data.csv) The input dataset contains $802$ samples corresponding to $802$ people who have been detected with different types of cancer. Each sample contains expression values of more than $20$K genes. Samples are categorized into one of the following types of tumors: BRCA, KIRC, COAD, LUAD and PRAD.

Following is an extended description of the tumors associated with this dataset:

-   [BRCA (Breast Cancer)]{.underline}: Breast cancer is one of the most common cancers among women. It originates in the breast tissue and can occur in both men and women.

-   [KIRC (Renal Cancer)]{.underline}: Renal cell carcinoma, or kidney cancer, occurs in the lining of small tubes in the kidney.

-   [COAD (Colon Cancer)]{.underline}: Colorectal cancer includes colon cancer (affecting the large intestine) and rectal cancer (affecting the rectum). Colon cancer is a major cause of cancer-related deaths.

-   [LUAD (Lung Cancer - *Adenocarcinoma*)]{.underline}: Lung *adenocarcinoma* is a subtype of non-small cell lung cancer. It originates in the cells lining the airways and is one of the most common types of lung cancer.

-   [PRAD (Prostate Cancer)]{.underline}: Prostate cancer occurs in the prostate, a small gland in men that produces seminal fluid. It is one of the most common cancers in men.

[**2. Estimated State-wise cancer incidences:**](https://sansad.in/getFile/loksabhaquestions/annex/1712/AU1399.pdf?source=pqals) The table provides estimated incidence of cancer cases in India by States and Union Territory-wise for all sites and for both sexes.

[**3. Gender-wise different sites of cancer:**](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10231735/table/ijmr_1821_22-t001/?report=objectonly) The table presents the estimated cancer incidence, number of cases, crude rate, and cumulative risk by sex and anatomical sites in India for the year $2022$.

Following is an extended description of the terminologies associated with this dataset:

-   [Cum-risk]{.underline}: Cumulative risk of developing cancer in the age range of $0$ to $74$ years. It represents the likelihood or probability of an individual developing cancer within this specified age range.

    $$
    \boxed{\text{Cumulative Risk} = \tfrac{\text{Number of Cancer Cases}}{\text{Total Population}} \times 100}
    $$

-   [Crude Rate (CR)]{.underline}: Crude rate refers to the total number of cancer cases occurring in a population divided by the total population, expressed as a rate per a specific unit of time (usually per $100,000$ population). It provides a general overview of cancer incidence within a population, without considering factors such as age distribution.

    $$
    \boxed{\text{Crude Rate}=\tfrac{\text{Number of Cancer Cases}}{\text{Total Population}}\times 100,000}
    $$

-   [Age-Adjusted Rate (AAR)]{.underline}: Age adjusted rate is a standardized rate that takes into account the age distribution of a population. It allows for fair comparisons of cancer rates between different populations or over time by removing the influence of age as a confounding factor. $$
    \boxed{\text{Age-Adjusted Rate
    }= \sum_{i=1}^n\left(\tfrac{\text{Age-specific rate}_i \times \text{Population}_i}{\text{Total Population}}\right) \times 100,000} $$

-   [Malig Imn.Prol D (Malignant Immunoproliferative Diseases)]{.underline}: This term refers to a group of disorders characterized by the abnormal proliferation of immune cells, leading to the development of malignancies. These diseases involve the uncontrolled growth of cells of the immune system, such as lymphocytes or plasma cells, and can include conditions like lymphomas, leukemias and multiple myeloma.

[**4. Age-wise cancer incidences:**](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10231735/table/ijmr_1821_22-t002/?report=objectonly) The table provides gender-disaggregated, estimated top five leading sites of cancer ($\%$) in India by age group ($0-14, 15-39, 40-64 \ \& \ 65^+$ age groups) for the year $2022$.

## Data Pre-processing and Cleaning

We conducted data pre-processing and cleaning tasks on two datasets: "`data.csv`" and "`labels.csv`". These datasets contain information related to cancer research, focusing specially on genetic data and associated labels.

**1. Essential Packages:** For this project, we utilized several essential packages in `R`, including `tibble`, `tidyverse` and `dplyr`.

**2. Pre-processing:** This step is very crucial pertaining to the complexity and volume of genetic data involved.

-   [Data Importing:]{.underline} Our code reads the CSV files "`data.csv`" and "`labels.csv`" into `R` as tibbles using the `read.csv()` function. These datasets contain genetic data and label information related to cancer research.

-   [Exploratory Data Analysis (EDA):]{.underline} We performed EDA to gain insights into the structure and content of the datasets. This involved examining the structure of both datasets using the `str()` function and displaying the first few entries of each dataset using the `head()` function.

-   [Categorical Variable Conversion:]{.underline} We converted some columns in the datasets from *character* type to *factor* type using the `as.factor()` function. This was necessary for categorical variables. We also converted the final dataframe into a more structured format, *tibble* to facilitate efficient analysis.

-   [Data Merging:]{.underline} We merged the two datasets into a single dataframe using the `cbind()` function, combining the label information with the genetic data.

-   [Data Quality Checks:]{.underline} We checked for null values (`is.null()`), NA values (`is.na()`), and duplicated entries (`duplicated()`) in the merged dataframe. The absence of such issues indicates clean data.

-   [Summary Statistics:]{.underline} We calculated summary statistics for the genetic data to understand its distribution and characteristics using the `summary()` function.

    ```{r}
    #| echo: false
    #| tbl-cap: Summary statistics for Genes 1 and 2
    kable(summary(df[c(4,5)]))
    ```

The processed dataframe contains both label information and genetic data. It is saved in the [ICMR.Rdata](https://drive.google.com/file/d/1deE-VbSUCll47XgUvrMothUlDm-s8Q_S/view?usp=drive_link) file for further analysis and modelling.

\newpage

## Data Insights

The data we have, has $20,534$ columns with $800$ rows, as mentioned in the description. And distribution of classes is given below:

```{r}
#| echo: false
#| layout-valign: bottom
#| fig-subcap: 
#|   - "Proportion of Classes"
#|   - "Histogram of Variance Range"
#| layout-ncol: 2
Can_lab <- df[c(1,2)]
Can_lab_tab <- data.frame(table(Can_lab$Class))
Can_lab_tab$Prop <- round(Can_lab_tab$Freq/sum(Can_lab_tab$Freq) * 100, 2)
Can_lab_tab$Prop <- paste(as.character(Can_lab_tab$Prop), "%", sep = "")
colnames(Can_lab_tab) <- c("Types", "Freq", "Prop")
ggplot(Can_lab_tab, aes(x = "", y = Freq, fill = Types)) +
  geom_bar(stat = "identity", width = 1, color = "white") +
  coord_polar("y", start = 0) +
  labs(title = "Distribution of Cancer Types") +
  theme_void() +
  geom_text(aes(label = Prop), color = "white",
            position = position_stack(vjust = c(0.5))) +
  scale_fill_brewer(palette="Set1")
vars <- apply (df[-c(1,2)],2,var)
# Calculate the range of variances
variance_range <- max(vars) - min(vars)
# Histogram
ggplot(data.frame(Variance = vars), aes(x = Variance)) +
  geom_histogram(bins = 20, fill = 'pink', color = 'black') +
  labs(x = 'Variance Range', y = 'Frequency', title = 'Histogram') +
  theme_minimal()
```

From the pie chart, we can see that instances for class BRCA are more than that of others followed by KIRC, LUAD and PRAD and class COAD has the least number of instances.

-   [Variance Threshold]{.underline}: From the graph, it's easy to see that most of the columns have low variance. Features with high variance have data points that are spread out over a wide range. These features are considered significant because they contain valuable information that can help in discriminating between different classes or categories. Similarly, features with low variance have data points that have little variation. Such features may not carry much discriminative power and can be considered less significant.

-   [Distribution of average gene expression levels]{.underline}: We calculated the average expression values for each gene across all samples, sorting them in descending order based on these averages. The top $5$ genes with the highest average expression values are displayed in a tabular format.

```{r}
#| echo: false
#| warning: false
#| tbl-cap: Genes with highest mean expression value
gene_names_df <- as.tibble(colnames(df)[-c(1,2)])
colnames(gene_names_df) <- "Gene"
gene_names_df$Gene <- as.factor(gene_names_df$Gene)
average_sorted_gene_expression <- gene_names_df %>% mutate(Expression=apply(df[-c(1,2)], 2, mean)) %>% arrange(desc(Expression))
kable(head(average_sorted_gene_expression, 5))
```

\newpage

Following this, we generated a histogram and density plot to illustrate the distribution of average gene expression values.

```{r}
#| echo: false
#| warning: false
#| fig-align: center
#| fig-cap: Distribution of mean gene expression levels
ggplot(average_sorted_gene_expression <- gene_names_df %>% mutate(Expression=apply(df[-c(1,2)], 2, mean)) %>% 
         arrange(desc(Expression)), aes(x = Expression)) +
  geom_histogram(binwidth = 0.3, fill = "#4B0082", color = "black", aes(y = ..density..), alpha = 0.7) +
  geom_density(fill = "#FF5733", alpha = 0.4) +
  labs(x = "Average Gene Expression", y = "Density") +
  theme_minimal()
```

[Boxplot of cases by gender]{.underline}:

```{r}
#| echo: false
#| fig-cap: Cases by Gender
#| warning: false
#| fig-align: center
#| fig-height: 2.55
load("Cancer_Sites.Rdata")
gender_labels <- c("0" = "Male", "1" = "Female", "2" = "Both")
gender_colors <- c("0" = "blue", "1" = "red", "2" = "green")
ggplot(dat, aes(x = factor(Gender), y = Cases, fill = factor(Gender))) +
  geom_boxplot() + scale_x_discrete(labels = gender_labels) +
  scale_fill_manual(values = gender_colors, labels = gender_labels) + 
  labs(title = "Boxplot", x = "Gender", y = "Cases") +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5))

```

\newpage

## Visualizations

### Age specific gender-wise cancer incidences

-   The density curve for females exhibits a [leptokurtic]{.underline} shape, indicating a higher concentration of data points around the mean and heavier tails compared to a normal distribution. In contrast, the density curve for males demonstrates a [mesokurtic]{.underline} shape, suggesting a distribution with moderate kurtosis and a balanced spread of data around the mean.

-   Our examination of the age-wise distribution of cancer patients across genders revealed a common trend characterized by a [negative skewness]{.underline}. This observation implies a tendency towards a longer tail on the left side of the distribution, indicating a higher frequency of cancer occurrences in older age groups compared to younger age groups, irrespective of gender.

```{r}
#| echo: false
#| fig-height: 5
#| warning: false
#| layout-ncol: 2
#| fig-subcap: 
#|           - "Stacked Histogram"
#|           - "Density Plots"
FRE_M <- c(21308, 74872, 341230, 274766)
dma <- rep(c(15,40,65,80), FRE_M)
hist(dma, breaks = c(0,15,40,65,80), xlim = c(0,100), 
     ylim = c(0.00105, 0.035),
     main = "Cancer Incidence Histogram",
     xlab = "Age", col=rgb(0, 0, 1, alpha=0.5))

FRE_F <- c(13709, 94166, 425918, 215458)
dfe <- rep(c(15,40,65,80), FRE_F)

hist(dfe, breaks = c(0,15,40,65,80), add=T, 
      col=rgb(1, 0, 0, alpha=0.5))
legend("topleft", legend=c("Male", "Female"), fill=c(rgb(0, 0, 1, alpha=0.5), rgb(1, 0, 0, alpha=0.5)))

FRE_F <- c(13709, 94166, 425918, 215458)
dfem <- rep(c(15,40, 65, 80), FRE_F)
### first decide the bandwidth
bw1 = 4.89
f <- density(dfem, bw = bw1)$x #female age values
density_f <- density(dfem, bw = bw1)$y #corresponding densities

### first decide the bandwidth
bw2 = 4.89
FRE_M <- c(21308, 74872, 341230, 274766)
dma <- rep(c(15,40, 65, 80), FRE_M)
m <- density(dma, bw = bw2)$x #male age values
density_m <- density(dma, bw = bw2)$y #corresponding densities

sorted_vals_f <- sort(f)
cum_density_f <- cumsum(density_f)
ecdf_f <- cum_density_f/sum(density_f) 
mu <- mean(sorted_vals_f)
sigma <- sd(sorted_vals_f)
normal_cdf <- pnorm(sorted_vals_f, mean = mu, sd = sigma)
scale_f = (sigma^2)/mu
shape_f = mu/scale_f
gamma_cdf <- pgamma(sorted_vals_f, shape = shape_f , scale = scale_f)
sorted_vals_m <- sort(m)
cum_density_m <- cumsum(density_m)
ecdf_m <- cum_density_m/sum(density_m) 
mu_m <- mean(sorted_vals_m)
sigma_m <- sd(sorted_vals_m)
normal_cdf_m <- pnorm(sorted_vals_m, mean = mu_m, sd = sigma_m)
scale_m = (sigma_m^2)/mu_m
shape_m = mu_m/scale_m
gamma_cdf_m <- pgamma(sorted_vals_m, shape = shape_m , scale = scale_m)
plot(f, density_f, type = "l", xlab = "Age",
     ylab = "density",col="red",lty=2, main="Estimated Cancer Incidence Density")
lines(m, density_m, type = "l", col="blue")
legend("topleft", legend = c("Male", "Female"), col = c("blue", "red"), lty = c(1,2))





```

### Gender-wise top ten cancer sites

[**Leading Cancer Sites Among Females**]{.underline}**:**

-   [Breast]{.underline} ($17.89\%$): Major risk factors include female gender, age, family history, genetic mutations (e.g., BRCA$1$ and BRCA$2$), hormonal factors (e.g., early menarche, late menopause), reproductive history and lifestyle factors.

-   [Genital System]{.underline} ($13.55\%$): This includes cancers of the cervix, uterus, ovaries, vagina and vulva. Risk factors vary by site but may include HPV infection, sexual activity, smoking, hormonal factors and genetic predisposition.

-   [Digestive System]{.underline} ($9.60\%$): This includes dietary habits, alcohol consumption, tobacco use and chronic conditions such as obesity and *gastroesophageal reflux disease* (GERD).

-   [Uterine Cervix]{.underline} ($6.55\%$): HPV infection is the primary risk factor, along with smoking, early sexual activity, multiple sexual partners and immuno-suppression.

-   [Oral Cavity and Pharynx]{.underline} ($4.35\%$): Risk factors include including tobacco and alcohol use, HPV infection and poor oral hygiene.

-   [Ovary]{.underline} ($3.82\%$): Risk factors include age, family history, nulliparity, infertility, hormonal factors and possibly endometriosis.

-   [Respiratory System]{.underline} ($2.83\%$) - [Lung and Bronchus]{.underline} ($2.31\%$): Similar risk factors to those in males, primarily smoking and occupational exposures.

-   [Uterine Corpus]{.underline} ($2.31\%$): Risk factors include hormonal factors (e.g., estrogen exposure), obesity, diabetes and certain genetic syndromes.

-   [Endocrine System]{.underline} ($2.31\%$): This includes cancers of the thyroid, adrenal glands and other endocrine organs. Risk factors vary by site but may include radiation exposure, family history and certain genetic syndromes.

```{r}
#| echo: false
#| fig-align: center
#| fig-cap: Top Ten Cancer Sites of Female
Site_1 <- read.csv("Site_M_F_Cancer.csv")
Site_1$M_Prop <- paste(as.character(round(Site_1$Male/sum(Site_1$Male) * 100, 2)),
                       "%", sep = "")
Site_1$F_Prop <- paste(as.character(round(Site_1$Female/sum(Site_1$Female) * 100, 2)),
                       "%", sep = "")
Site <- Site_1[-54,]
M_Site <- Site[-3]
F_Site <- Site[-2]
M_Site_ord <- M_Site[order(Site$Male, decreasing = FALSE),]
F_Site_ord <- F_Site[order(Site$Female, decreasing = FALSE),]
m_t <- tail(M_Site_ord, 10)
f_t <- tail(F_Site_ord, 10)
ggplot(f_t, aes(x = reorder(Site, Female), y = Female)) +
  geom_bar(stat = "identity", fill = "deepskyblue3") +
  geom_text(aes(label = F_Prop), color = "black", 
            position = position_stack(vjust = 1), hjust = -0.03) +
  labs(title = "Top Ten Cancer Sites",
       y = "Frequency", x = "Cancer Site") +
  theme(panel.background = element_blank(),
        axis.line.x = element_line("gray40"),
        axis.line.y = element_line("gray40")) +
  scale_y_continuous(limits = c(0, 250000), expand = c(0,0)) +
  coord_flip()

```

[**Leading Cancer Sites Among Males**]{.underline}**:**

-   [Digestive System]{.underline} ($13.06\%$): This includes cancers of the esophagus, stomach, liver, pancreas and colorectal region. Risk factors may include tobacco and alcohol use, dietary habits (e.g., high intake of processed meats) and chronic conditions such as *gastroesophageal reflux disease* (GERD) and *inflammatory bowel disease* (IBD).

-   [Oral Cavity and Pharynx]{.underline} ($11.07\%$): Major risk factors include tobacco use (both smoking and smokeless tobacco), heavy alcohol consumption, *human papillomavirus* (HPV) infection and poor oral hygiene.

-   [Respiratory System]{.underline} ($8.26\%$) - [Lung and Bronchus]{.underline} ($5.73\%$): Smoking, including exposure to secondhand smoke, is the primary risk factor for lung cancer. Occupational exposures to carcinogens such as asbestos, radon and diesel exhaust can also contribute.

-   [Mouth]{.underline} ($4.57\%$): Similar risk factors to oral cavity and pharynx cancers, including tobacco and alcohol use, HPV infection and poor oral hygiene.

-   [Genital System]{.underline} ($4.15\%$) - [Prostate]{.underline} ($3.32\%$): Prostate cancer is influenced by age, family history, and possibly dietary factors. Genetic predisposition and hormonal factors, particularly testosterone, play significant roles.

-   [Tongue]{.underline} ($3.18\%$) - [Other Oral Cavity]{.underline} ($3.09\%$): Risk factors are similar to those for oral cavity and pharynx cancers, including tobacco and alcohol use, HPV infection and poor oral hygiene.

-   [Urinary System]{.underline} ($2.65\%$): This includes cancers of the bladder, kidney and other urinary organs. Risk factors include smoking, occupational exposures, certain medications and genetic factors.

```{r}
#| echo: false
#| fig-align: center
#| fig-cap: Top Ten Cancer Sites of Male
ggplot(m_t, aes(x = reorder(Site, Male), y = Male)) +
  geom_bar(stat = "identity", fill = "cornflowerblue") +
  geom_text(aes(label = M_Prop), color = "black", 
            position = position_stack(vjust = 1), hjust = -0.03) +
  labs(title = "Top Ten Cancer Sites",
       y = "Frequency", x = "Cancer Site") +
  theme(panel.background = element_blank(),
        axis.line.x = element_line("gray40"),
        axis.line.y = element_line("gray40")) +
  scale_y_continuous(limits = c(0, 200000), expand = c(0,0)) +
  coord_flip()  
```

\newpage

## Spatial Analysis

-   Northern and eastern parts of India show lower cancer incidence compared to regions like Uttar Pradesh, Maharashtra, Bihar, West Bengal, Hyderabad and Tamil Nadu. Hilly areas and Andaman Nicobar islands exhibit lower cancer rates compared to the plains. Western and southeastern parts of India demonstrate moderate cancer incidence.

-   Uttar Pradesh stands out as having the highest cancer incidence among Indian states. Maharashtra, Bihar, West Bengal, Hyderabad and Tamil Nadu also exhibit high numbers of cancer cases.

-   Factors such as pollution, industrial activities and exposure to carcinogens may contribute to higher cancer rates in certain regions.

-   Clean and less polluted environments in hilly areas may contribute to lower cancer rates. Differences in lifestyle patterns, including dietary habits and physical activity levels, may also play a role in the observed regional disparities.

![Cancer Incidence of India in the year 2022](India_Map_Cancer_2022.png){fig-align="center" width="599" height="504"}

\newpage

We performed a comparative $10$ year gap analysis with the cancer incidences in years, $2011$ and $2021$ respectively.

-   We observed that Karnataka had improved over in cancer eradication whereas Hyderabad plunged to an increment in the number of cancer cases. The Telangana state, formed in $2$ June, $2014$, had less amount of cancer cases in $2021$. Ladakh was formed as a Union Territory in $31$ October, $2019$. It showed few cancer patients in $2021$, possibly due to its smaller population ratio.

-   West Bengal displayed very slight changes in the cancer incidence ratio (i.e., $\tfrac{\text{Total no. of cancer patients in that state}}{\text{Total no. of cancer patients in India}}$) over the $10$-year period.

-   In a quick snapshot, there is a massive increment in the total number of cancer patients nationwide from approximately $160,000$ in $2011$ to around $200,000$ in $2021$. This substantial increase underscores the importance of heightened attention from both the public and government sectors towards cancer eradication efforts and mass awareness campaigns.

![A comparative 10 Year Gap Cancer Incidence in India](India_Map_2011_2021.png){width="7.45in"}

\newpage

## Principal Component Analysis

Having high dimensionality or feature space can lead model to perform poorly known as the "*Curse of Dimensionality*". To deal with this, we reduce the feature space by performing the dimension reduction technique, Principal Component Analysis (PCA) and we consider $95\%$ variance explainability.

Each sample has expression values for around $20$K genes. However, it may not be necessary to include all $20$K gene expression values to analyze each cancer type. Therefore, we need to identify a smaller set of attributes which would then be used to fit multiclass classification models. So, the first task targets dimensionality reduction using PCA.

![](download1.png){fig-align="center" width="466"}

-   PCA effectively reduces the high-dimensional data to $2$-dimensions and provides insights into the distribution of different cancer types. The use of color to represent different cancer types allows for easy differentiation and understanding of the data.

-   This plot shows that there are distinct clusters formed by different cancer types, indicating that the gene expression patterns vary across different cancer types.

-   Although some genes overlap between the clusters, the plot does not show any clear separation between all cancer types.

\newpage

[\textbf{Cumulative Explained Variance Plot}]{.underline}:

![](download2.png){fig-align="center" width="448"}

-   This plot typically shows the cumulative sum of explained variances explained on the Y-axis and the number of principal components on the X-axis.

-   As more principal components are added, the cumulative proportion of variance increases.

-   It helps in identifying the point at which adding more principal components does not significantly increase the explained variance, which can be a good guide for determining the appropriate number of principal components to retain.

-   The '*elbow*' or point where the curve starts to level off is often used to decide how many components one wants to keep.

-   From this curve, we see that it starts to flatten around $150$ - $200$ PCs, suggesting a potential elbow point in this range.

\newpage

[**Remarks**]{.underline}**:**

-   Class PRAD is notably more separable than other classes, indicating effective feature differentiation.

-   PC$1$ and PC$3$ hold valuable information for distinguishing KIRC and PRAD from other cancer types.

-   Classes PRAD and COAD exhibit enhanced separability, emphasizing the significance of PC$3$ and PC$4$.

-   PC$3$ and PC$4$ capture distinctive features for characterizing PRAD, making it more distinguishable.

::: {#fig-2 layout-nrow="2"}
![PC1 vs PC3](pca1vs3.png){#fig-c fig-align="center" width="3.84in"}

![PC3 vs PC4](pca3vs4.png){#fig-d fig-align="center" width="3.84in"}

Scatter Plot of Data Distribution Based on Principal Components
:::

\newpage

## Parametric Tests

### Multiple F-tests

We want to determine whether means of gene information encoded by a particular gene (*response*) differ statistically significantly among the independent cancer groups (*covariates*). In this case, with reference to the `ICMR` dataset, the independent categorical variable is the '`Class`' column which represents the $5$ different cancer types. The dependent variable is the gene expression levels of a specific gene. We analyze each gene individually in this setup, making it [multiple F-tests]{.underline}.

We have,

-   $5$ groups (categories of cancer types)

-   $n_i$ observations in the $i^{\text{th}}$ group (where $i=1,2,\ldots,5$)

-   $N$ total observations ($N = n_1+n_2+\ldots+n_5$)

-   $X_{ij}$ is the observation in the $i^{\text{th}}$ group and the $j^{\text{th}}$ gene expression level ($j=1,2,\ldots,20532$)

-   $\overline{X_n} \stackrel{asym}{\sim} \mathcal{N}(\mu,\,\tfrac{\sigma^{2}}{n})$ i.e.,$\dfrac{\sqrt{n}(\overline{X_n}-\mu)}{\sigma}\xrightarrow[]{d} \mathcal{N}(0,\,1) \text{ as } \boxed{n \rightarrow \infty}$ (by [Central Limit Theorem]{.underline}) where $\overline{X_n}$ is a random variable with mean $\mu$ and variance $\tfrac{\sigma^2}{n}$ that denotes mean gene expression for a particular gene.

The null hypothesis ($\text{H}_0$) for each F-test is that there are no differences in mean gene expression levels among the different cancer types. $$\text{H}_0: \mu_1=\mu_2=\ldots=\mu_5$$ where: $\mu_{i}$ is the population mean of the $i^{\text{th}}$ group.

The alternative hypothesis ($\text{H}_1$) is that at least one pair of mean gene expression levels is different. $$\text{H}_1: \text{At least one} \ Î¼_{i} \text{ is different from the others.}$$ To test these hypotheses, we calculate the F-statistic: $\text{F}=\tfrac{\text{Between-group variance}}{\text{Within-group variance}}$

[Rejection Criteria]{.underline}: If the p-value associated with the F-statistic is below a certain threshold (typically $0.05$), we reject the null hypothesis.

```{r}
#| echo: false
#| layout-ncol: 2
X <- as.matrix(df[ , -c(1,2)]) 
y <- df$Class  
X_scaled <- scale(X)
result_df <- data.frame(
  Gene = character(),
  F_statistic = numeric(),
  p_value = numeric(),
  variance = numeric(),
  stringsAsFactors = FALSE
)
anova_results <- list()
for (i in 1:ncol(X_scaled)) 
  {
  gene_expression <- X_scaled[, i]
  if (any(is.na(gene_expression))) 
    {
    next
  }
  if (sd(gene_expression) == 0) 
    {
    next
  }
  group_expressions <- split(gene_expression, y)
  anova_result <- summary(aov(formula = gene_expression ~ y))
  if (anova_result[[1]]$`Pr(>F)`[1] < 0.05) 
    { 
    f_statistic <- anova_result[[1]]$`F value`[1]
    p_value <- anova_result[[1]]$`Pr(>F)`[1]
    variance <- var(X[,i])
    gene_name <- paste("gene", i-1, sep = "_")
    result_df <- rbind(result_df, data.frame(Gene = gene_name, F_statistic = f_statistic, p_value = p_value,variance = variance))
  }
}
p_values <- result_df$p_value
corrected_pvals <- p.adjust(p_values, method = "fdr")
result_df$p_value <- corrected_pvals
result_df <- result_df[result_df$p_value<0.05, ]
variances_sorted <- result_df %>% arrange(desc(variance))
kable(head(variances_sorted, 3), caption = "Top 3 high variance genes")
kable(tail(variances_sorted, 3), caption = "Bottom 3 high variance genes", row.names = FALSE)
```

\newpage

### One vs. All t-test

In a one-vs-all t-test scenario, we compare the means of one cancer group (the "*one*" group) against the means of all other groups excluding that cancer group (the "*all*" group). It's commonly used in situations where one wants to compare a specific group against the rest of the data.

|                       |                                                                                                                                                                                               |
|---------------------|------------------------------------------------|
| **Independence**      | Gene expressions within the "*one*" group and "*all*" group are independent of each other.                                                                                                    |
| **Normality**         | Each group's data follow approximately the normal distribution (by [Central Limit Theorem]{.underline}).                                                                                      |
| **Random Sampling**   | The collective gene expressions data are obtained through a random sampling process from the population of cancer patients. This ensures that the sample is representative of the population. |
| **Unequal Variances** | The compared variances of the two groups are unequal.                                                                                                                                         |

: Assumptions

-   [Null Hypothesis]{.underline} ($\text{H}_0$): The null hypothesis assumes that there is no difference between the means of the "*one*" group and the means of the "*all*" group. $$\text{H}_0:\mu_\text{one}=\mu_\text{all}$$

-   [Alternative Hypothesis]{.underline} ($\text{H}_1$): The alternative hypothesis states that the means of the "*one*" group and the "*all*" group are different. $$\text{H}_1:\mu_\text{one}\neq\mu_\text{all}$$

-   [Test Statistic]{.underline}: $t_\text{cal} \stackrel{\text{H}_0}{=} \dfrac{\bar{x_1}-\bar{x_2}}{\sqrt{\dfrac{s_1^2}{n_1}+ \dfrac{s_2^2}{n_2} } }$ where:

    -   $\bar{x_1}$ and $\bar{x_2}$ are the means of the "*one*" group and the "*all*" group respectively.
    -   $s_1$ and $s_2$ are the standard deviations of the "*one*" group and the "*all*" group respectively.
    -   $n_1$ and $n_2$ are the sample sizes of the "*one*" group and the "*all*" group respectively.

-   [Rejection Criteria]{.underline}: If the p-value is smaller than a predetermined significance level (commonly $0.05$), we reject the null hypothesis. Else, we fail to reject $\text{H}_0$ and further data analysis is required.

    \newpage

-   [Results]{.underline}: We performed this test for the top $3$ high variance genes.

```{r}
#| echo: false
#| cache: false
perform_one_vs_all_ttests <- function(df, gene) {
  unique_cancer_types <- unique(df$Class)
  p_values <- numeric(length(unique_cancer_types))
  
  for (i in seq_along(unique_cancer_types)) {
    cancer_type <- unique_cancer_types[i]
    group1 <- df[df$Class == cancer_type, gene]
    group2 <- df[df$Class != cancer_type, gene]
    t_test_result <- t.test(group1, group2, var.equal = FALSE)
    p_val <- p.adjust(t_test_result$p.value, method = "fdr")
    p_values[i] <- p_val
    cat(paste(cancer_type, "vs. All for", gene, ": p-value =", format(p_val, digits = 8)), "\n")
  }
  corrected_p_values <- p.adjust(p_values, method = "fdr")
  return(corrected_p_values)
}
selected_genes <- head(variances_sorted$Gene, 3)  
corrected_p_values_list <- list()
for (gene in selected_genes) {
  cat(paste("Performing 'one vs. all' t-tests for", gene, ":\n"))
  perform_one_vs_all_ttests(df, gene)
}
```

\newpage

## Multinomial Logistic Regression

-   [Goal]{.underline}: We want to fit Logistic Regression for predicting the probability of the occurrence of $5$ different types of cancer for an individual.

-   [Motivation]{.underline}: Cancer types across different sites are of penultimate importance, particularly in studying the genetic effects on these cancer types. One common question that arises is that to which extent do genetics influences these cancers. Our dataset primarily focuses on $5$ types of cancer: BRCA, COAD, KIRC, LUAD and PRAD. Through Principle Component Analysis (PCA), we have determined that the first $500$ genes capture the maximum variation. Now, we aim to investigate whether these genes exhibit any significant effects on these cancer types.

So, here we consider the different types of cancer as distinct labels, each associated with corresponding gene expression values. Our interest lies in fitting a Multinomial Logistic Regression Model. Let us examine the following table, which defines the probabilities of occurrence for each cancer type.

```{=tex}
\begin{table}[ht]
\centering
\caption{Cancer Types with Corresponding Probabilities for $j^\text{th}$ individual}
\begin{tabular}{|c|ccccc|c|}
\hline
Sl. No. & 1 & 2 & 3 & 4 & 5 & \\
\hline
Cancer Types & BRCA & COAD & KIRC & LUAD & PRAD & Total\\
\hline
Probability & $\pi_{1j}$ & $\pi_{2j}$ & $\pi_{3j}$ & $\pi_{4j}$ & $\pi_{5j}$ & 1\\
\hline
\end{tabular}
\end{table}
```
Now, from this we observe that $\sum_{i=1}^{5}\pi_{ij} = 1$ so, $\pi_{5j} = 1-\sum_{i=1}^{4}\pi_{ij}$, considering $5^\text{th}$ category as the Pivotal Category. Thus, it is good enough to estimate $\pi_i$ ; $i=1,2,3,4$ and we can automatically get back the estimated value of $\pi_5$ which in turn will also reduce our manual labour.

\underline{\textbf{Model:}} Let $Y_j$ be the random variable of the occurrence of a type of cancer of $j^{\text{th}}$ person, \begin{equation*}
    Y_j =
    \begin{cases}
        1 & \text{if BRCA occurred}\\
        2 & \text{if COAD occurred}\\
        3 & \text{if KIRC occurred}\\
        4 & \text{if LUAD occurred}\\
        5 & \text{if PRAD occurred}\\
    \end{cases}
\end{equation*} which means \begin{equation*}
    Y_j =
    \begin{cases}
        1 & \text{with probability } \pi_{1j}\\
        2 & \text{with probability } \pi_{2j}\\
        3 & \text{with probability } \pi_{3j}\\
        4 & \text{with probability } \pi_{4j}\\
        5 & \text{with probability } \pi_{5j} = 1-\sum_{i=1}^{4}\pi_{ij}\\
    \end{cases}
\end{equation*}

Therefore, $P(Y_j = i) = \pi_{ij} = \frac{e^{\boldsymbol{X^T_j\beta_i}}}{1+\sum_{i=1}^{4}e^{\boldsymbol{X^T_j\beta_i}}}$ ; $i = 1,2,3,4$

Now by Maximum Likelihood Estimation we try to maximize the likelihood function, $$L(\beta) = L(\beta_1, \beta_2, \beta_3,\beta_4) = \prod_{j = 1}^{n} \left[\left\{\prod_{i=1}^{4} \left( \frac{e^{\boldsymbol{X^T_j\beta_i}}}{1+\sum_{i=1}^{4}e^{\boldsymbol{X^T_j\beta_i}}} \right)^{\mathbb{I}(Y_j=i)}\right\} \left( \frac{1}{1+\sum_{i=1}^{4}e^{\boldsymbol{X^T_j\beta_i}}} \right)^{\mathbb{I}(Y_j=5)} \right]$$ in order to fit the model. We can maximize it by various numerical ways.

Let us consider only Gene -$1$ first.

```{=tex}
\begin{table}[ht]
\centering
\caption{Estimates and p-values of the regression coefficients}
\begin{tabular}{c|cccc}
\hline
 Coefficients & Estimate & Std. Error & z value & Pr(>|z|) \\
\hline
(Intercept):1 &  2.345370 &  0.343819 &  6.822 & $9.01\times 10^{-12}$ \\
(Intercept):2 & -0.547328 &  0.494891 & -1.106  &  0.269 \\
(Intercept):3 & 2.398823  & 0.365845  & 6.557 & $5.49\times10^{-11}$ \\
(Intercept):4 & 0.296070  & 0.411232  & 0.720 & 0.472\\
$gene_1:1$ & -0.492740  & 0.099693 & -4.943 & $7.71\times 10^{-07}$ \\
$gene_1:2$ & -0.002505 &  0.137841 & -0.018  &  0.985 \\
$gene_1:3$ & -0.787602 & 0.112672 & -6.990 & $2.75\times 10^{-12}$ \\
$gene_1:4$ & -0.076462 &  0.115619  & -0.661  &  0.508 \\
\hline
\end{tabular}
\end{table}
```
Here from the p-values, we can see that Gene -$1$ has significant effects in causing BRCA and KIRC, at level $0.05$. For further, see [**Appendix**]{.underline}.

Now, let us fit the model and obtain the predicted probabilities of different types of cancer.

Let us consider two individuals with gene expression values of Gene -$1$ as $3.4678533$ and $2.9411814$. Then the fitted probabilites are as follows:

```{=tex}
\begin{table}[ht]
\centering
\caption{Fitted Probabilities of the Specified Two Individiuals}
\begin{tabular}{c|ccccc}
\hline
Individual & BRCA & COAD & KIRC & LUAD & PRAD\\
\hline
1 & 0.3626322 & 0.11002989 & 0.1375935 & 0.1978839 & 0.1918605\\
2 & 0.3962039 & 0.09286059 & 0.1755878 & 0.1736390 & 0.1617087\\
\hline
\end{tabular}
\end{table}
```
From this, we can see that for the first individual, according to the gene expression value of Gene -$1$, there is greater probability of occurring BRCA. For the second person, the scenario is more or less the same.

Again, let us check it for Gene -$1$ and Gene -$2$ collectively.

Now, let us fit the model and obtain the predicted probabilities of different types of cancer.

Let us consider two individuals with gene expression values of Gene -$1$ and Gene -$2$ as follows: $3.4678533$, $2.9411814$ and $2.9411814$, $2.6632763$ respectively. Then the fitted probabilites are:

```{=tex}
\begin{table}[ht]
\centering
\caption{Fitted Probabilities of the Specified Two Individiual}
\begin{tabular}{c|ccccc}
\hline
Individual & BRCA & COAD & KIRC & LUAD & PRAD\\
\hline
1 & 0.3461035 & 0.1183316 & 0.1068651 & 0.2312489 & 0.19745091\\
2 & 0.4627836 & 0.1008106 & 0.2074741 & 0.1551230 & 0.07380868\\
\hline
\end{tabular}
\end{table}
```
From this, we can see that for the first individual, according to the gene expression value of Gene -$1$, there is greater probability of occurring BRCA. For the second person, the scenario is more or less the same.

\newpage

## Non-Parametric Tests

### Shapiro-Wilk Normality Test

In our analysis, we have used this test in two different cases. At first, we had to check whether the gene expression values in the dataset, [ICMR.Rdata](https://drive.google.com/file/d/1deE-VbSUCll47XgUvrMothUlDm-s8Q_S/view?usp=drive_link) are normally distributed or not. Secondly, we used it to check whether the ages of male and female cancer patients are normally distributed. This is performed using the `R` function called `shapiro.test()`. For further details see [\textbf{Appendix}]{.underline}.

**Testing for Gene Expression Values**

Here expressions of $20,532$ different genes are recorded. Among them only $1,767$ gene expressions can be considered to be normally distributed at $5\%$ level of significance. Each of the $20,532$ genes are tested for normality individually. Each gene has $800$ different expression values.

We have,

-   $X_{i_{1}}, X_{i_{2}},...,X_{i_{n}}\overset{iid}{\sim}F_{i}(x)$ where $X_{i_{j}}$ is the $j^{th}$ expression value for the $i^{th}$ gene. Here $i=1, 2, 3, ....,20532$ and $j=1,2,....800$.
-   The distribution functions $F_{i}$ are assumed to be absolutely continuous $\forall{i}$.
-   The test is a level $\alpha=0.05$ both sided test.

The $i^{th}$ null hypothesis $H_{i0}$ is that the $i^{th}$ gene expression comes from $\Phi_{i}$ which is the normal distribution function. The corresponding alternative hypotheses are opposite. $$H_{i0} : F_{i}=\Phi_{i} \text{ against } H_{ia} : F_{i}\neq \Phi_{i} \text{  }\forall{i}$$

The $i^{th}$ Wilk-Shapiro test statistic is, $$
W_{i} = \frac{(\sum_{j=1}^{800} a_{i_{j}}X_{i_{(j)}})^2}{(\sum_{j=1}^{800} (X_{i_{j}}-\bar{X}_{i})^2)} \text{        where    } a_{i_{j}} = (a_{i_{1}}, a_{i_{2}}, ...a_{i_{n}}) = \frac{m^TV^{-1}}{(m^TV^{-1}V^{-1}m)^{1/2}} 
$$

-   $X_{i_{(j)}}$ \text{and} $\bar{X}_{i}$ are the $j^{th}$ order statistics and the $i^{th}$ sample mean respectively.

-   $m_{i}=(m_{i_{1}},m_{i_{2}}, ...m_{i_{800}})^{1/2}$ are the expected values of the order statistics of independent and identically distributed random variables sampled from the standard normal distribution.

-   $V_{i}$ is the covariance matrix of those order statistics of the $i^{th}$ sample.

-   [Rejection Criteria]{.underline}: If the p-value is smaller than a pre-determined significance level $\alpha$, we reject $H_{0}$.

\newpage

[\textbf{Findings}]{.underline}: After running Shapiro-Wilk Test on each of the 20,532 genes' expression values, we assembled all the informations like name of the genes, W-Statistic values, p-values and accept-reject decisions into a single dataframe named [shapiro.csv](https://github.com/royalsky13/MTH209-Group-Project/blob/main/Statistical%20Data%20Analysis/shapiro.csv). The output is displayed below through tables.

```{=tex}
\begin{table}[htbp]
    \centering
    \caption{5 Random draws of rows}
    \begin{tabular}{c|c|c|c}
        \hline
        Gene & W & p-value & Rejected \\
        \hline
        gene\_12090 & 0.9534434 & 9.950693e-15 & TRUE \\
        gene\_11126 & 0.9977158 & 3.538067e-01 & FALSE \\
        gene\_1929 & 0.9921550 & 3.997301e-04 & TRUE \\
        gene\_14104 & 0.9828147 & 8.043263e-08 & TRUE \\
        gene\_11549 & 0.9887918 & 1.271188e-05 & TRUE \\
        \hline
    \end{tabular}
\end{table}
```
The table below shows the genes which have the highest p-values. That means these genes' expression values are very likely to be normally distributed.

```{=tex}
\begin{table}[htbp]
    \centering
    \caption{Top 4 normally distributed gene expressions}
    \begin{tabular}{c|c|c|c}
        \hline
        Gene & W & p-value & Rejected \\
        \hline
        gene\_18776 & 0.99939029519 & 0.9977 & FALSE \\
        gene\_13337 & 0.99929787407 & 0.9937 & FALSE \\
        gene\_745 & 0.99921778732 & 0.9872 & FALSE \\
        gene\_4471 & 0.99921284749 & 0.9867 & FALSE \\
        \hline
    \end{tabular}
\end{table}
```
\newpage

**Testing for Normality of Cancer Patients' Age**

Here age data of $1,461,427$ cancer patients are recorded. Among them $749,251$ patients are female and $712,176$ patients are male. We have tested whether this data is normally distributed.

We have,

-   $X_{i_{1}}, X_{i_{2}},...,X_{i_{n_{i}}}\overset{iid}{\sim}F_{i}(x)$ where $X_{i_{j}}$ is the $j^{th}$ person of the $i^{th}$ gender. Here $i \in \{f,m\}$ and $j=1,2,....n_{i}$ where $n_{m}=712176$, $n_{f}=749251$
-   The distribution functions $F_{i}$ are assumed to be absolutely continuous $\forall{i}$.
-   The test is a level $\alpha=0.05$ both sided test.

The $i^{th}$ null hypothesis $H_{i0}$ is that the $i^{th}$ age sample comes from $\Phi_{i}$ which is the normal distribution function. The corresponding alternative hypotheses are opposite. $$H_{i0} : F_{i}=\Phi_{i} \text{ against } H_{ia} : F_{i}\neq \Phi_{i} \text{  }\forall{i}$$

The $i^{th}$ Wilk-Shapiro test statistic is, $$
W_{i} = \frac{(\sum_{j=1}^{n_{i}} a_{i_{j}}X_{i_{(j)}})^2}{(\sum_{j=1}^{n_{i}} (X_{i_{j}}-\bar{X}_{i})^2)} \text{        where    } a_{i_{j}} = (a_{i_{1}}, a_{i_{2}}, ...a_{i_{n_{i}}}) = \frac{m^TV^{-1}}{(m^TV^{-1}V^{-1}m)^{1/2}} 
$$

-   $X_{i_{(j)}}$ \text{and} $\bar{X}_{i}$ are the $j^{th}$ order statistics and the $i^{th}$ sample mean respectively.

-   $m_{i}=(m_{i_{1}},m_{i_{2}}, ...m_{i_{n_{i}}})^{1/2}$ are the expected values of the order statistics of independent and identically distributed random variables sampled from the standard normal distribution.

-   $V_{i}$ is the covariance matrix of those order statistics of the $i^{th}$ sample.

-   [Rejection Criteria]{.underline}: If the p-value is less than $\alpha = 0.5$, we reject $H_{0}$.

[\textbf{Findings}]{.underline}: Here it turns out that the age distribution of \underline{female} cancer patients are very less likely to have normal distribution. As the p-value of the test is $p_{f} < 0.05$. So, $H_{f0}$ is rejected at 5% level of significance.

```{r}
#| echo: false
##Generating a synthetic dataset for female cancer patients 
FRE_F <- c(13709, 94166, 425918, 215458)
dfem <- rep(c(15,40, 65, 80), FRE_F)

### first decide the bandwidth
bw1 = 4.89
f <- density(dfem, bw = bw1)$x #female age values
shapiro.test(f)
```

Similarly, as $p_{m}<0.05$ the null hypothesis $H_{m0}$ is rejected at 5% level of significance. Therefore, it is safe to say age of male cancer patients are not normally distributed.

```{r}
#| echo: false
## Generating a synthetic dataset for female cancer patients 
FRE_M <- c(21308, 74872, 341230, 274766)
dma <- rep(c(15,40, 65, 80), FRE_M)

### first decide the bandwidth
bw2 = 4.89
m <- density(dma, bw = bw2)$x #male age values
shapiro.test(m)
```

### Kolmogorov-Smirnov Test

#### One Sample Test

Previously, we performed Shapiro-Wilk test to check the normality of the age of cancer patients. WS test works better for checking whether the data is normal or not. But, to check about the other distribution we are using very popular Kolmogorov-Smirnov test. For theory, see [\textbf{Appendix}]{.underline}.

We have,

-   $X_{i_{1}}, X_{i_{2}},...,X_{i_{n_{i}}}\overset{iid}{\sim}F_{i}(x)$ where $X_{i_{j}}$ is the $j^{th}$ person of the $i^{th}$ gender. Here $i \in \{f,m\}$ and $j=1,2,....n_{i}$ where $n_{m}=712176$, $n_{f}=749251$.
-   The distribution functions $F_{i}$ are assumed to be absolutely continuous $\forall{i}$.
-   The test is a level $\alpha=0.05$ both sided test.

The $i^{th}$ null hypothesis $H_{i0}$ is that the $i^{th}$ age sample comes from $\Gamma_{i}$ which is the gamma distribution function. The corresponding alternative hypotheses are opposite. $$H_{i0} : F_{i}=\Gamma_{i} \text{ against } H_{ia} : F_{i}\neq \Gamma_{i} \text{  }\forall{i}$$

The Kolmogorov-Smirnov test statistics are, $$
D_{n_{m}} = \max_x |S_{n_{m}}(x) - \Gamma_{m}(x)| \text{ } \text{ } \text{ and } \text{ } \text{ }
D_{n_{f}} = \max_x |S_{n_{f}}(x) - \Gamma_{f}(x)|
$$

-   $S_{n_{m}}(x)$ and $S_{n_{f}}(f)$ are respectively the empirical distribution function of male and female age sample.

-   [Rejection Criteria]{.underline}: If the p-value is less than $\alpha = 0.5$, we reject $H_{0}$.

\newpage

[\textbf{Findings}]{.underline}: Here it turns out that the age distribution of \underline{female} cancer patients are very less likely to have gamma distribution. As the p-value of the test is $p_{f} < 0.05$. So, $H_{f0}$ is rejected at 5% level of significance.

```{r}
#| echo: false
#KS Test Code
FRE_F <- c(13709, 94166, 425918, 215458)
dfem <- rep(c(15,40, 65, 80), FRE_F)

### first decide the bandwidth
bw1 = 4.89
f <- density(dfem, bw = bw1)$x #female age values
density_f <- density(dfem, bw = bw1)$y #corresponding densities


########## Now we calculate the  empirical distribution function
sorted_vals_f <- sort(f)
#cumulative density
cum_density_f <- cumsum(density_f)
ecdf_f <- cum_density_f/sum(density_f) 


###### Plotting the normal cdf for female
#plotting normal cdf
# Calculate normal CDF for female
mu <- mean(sorted_vals_f)
sigma <- sd(sorted_vals_f)
normal_cdf <- pnorm(sorted_vals_f, mean = mu, sd = sigma)




######Calculating Gamma CDF for female
scale_f = (sigma^2)/mu
shape_f = mu/scale_f
gamma_cdf <- pgamma(sorted_vals_f, shape = shape_f , scale = scale_f)


##### KS Test
ks.test(f, "pgamma", shape_f, scale_f)
```

Similarly, as $p_{m}<0.05$ the null hypothesis $H_{m0}$ is rejected at 5% level of significance. Therefore, it is safe to say age of male cancer patients are not gamma distributed.

```{r}
#| echo: false
############## For males


##Generating a synthetic dataset for female cancer patients 
FRE_M <- c(21308, 74872, 341230, 274766)
dma <- rep(c(15,40, 65, 80), FRE_M)

### first decide the bandwidth
bw2 = 4.89
m <- density(dma, bw = bw2)$x #male age values
density_m <- density(dma, bw = bw2)$y #corresponding densities



########## Now we calculate the  empirical distribution function
sorted_vals_m <- sort(m)
#cumulative density
cum_density_m <- cumsum(density_m)

ecdf_m <- cum_density_m/sum(density_m) 


###### Plotting the normal cdf 
#plotting normal cdf
# Calculate normal CDF
mu_m <- mean(sorted_vals_m)
sigma_m <- sd(sorted_vals_m)
normal_cdf_m <- pnorm(sorted_vals_m, mean = mu_m, sd = sigma_m)




######Calculating Gamma CDF
scale_m = (sigma_m^2)/mu_m
shape_m = mu_m/scale_m
gamma_cdf_m <- pgamma(sorted_vals_m, shape = shape_m , scale = scale_m)

ks.test(m, "pgamma", shape_m, scale_m) #testing whether gamma dist or not
```

We have summarised our findings from the above in the following plots given below:

```{r}
#| layout-ncol: 2
#| echo: false
#| fig-height: 6
plot(sorted_vals_f, ecdf_f, type = "s", 
     main = "Empirical CDF", xlab = "Age of female cancer patients", ylab = "Cumulative Probability")
lines(sorted_vals_f, normal_cdf, col = "red")

lines(sorted_vals_f, gamma_cdf, col = "green")
legend("topleft", legend = c("Empirical CDF", "Normal CDF", "Gamma CDF"), 
       lty = 1, col = c("black", "red", "green"))
########## Now we calculate the  empirical distribution function
plot(sorted_vals_m, ecdf_m, type = "s", 
     main = "Empirical CDF", xlab = "Age of male cancer patients", ylab = "Cumulative Probability")
###### Plotting the normal cdf 
lines(sorted_vals_m, normal_cdf_m, col = "red")
######Calculating Gamma CDF
lines(sorted_vals_m, gamma_cdf_m, col = "green")
legend("topleft", legend = c("Empirical CDF", "Normal CDF", "Gamma CDF"), 
       lty = 1, col = c("black", "red", "green"))
```

\newpage

#### Two Sample Test

Now we will test whether the age of male cancer patients and female cancer patients come from the same population or not by two sample KS Test. For theory, see [\textbf{Appendix}]{.underline}.

We have,

-   $X_{i_{1}}, X_{i_{2}},...,X_{i_{n_{i}}}\overset{iid}{\sim}F_{i}(x)$ where $X_{i_{j}}$ is the $j^{th}$ person of the $i^{th}$ gender. Here $i \in \{f,m\}$ and $j=1,2,....n_{i}$ where $n_{m}=712176$, $n_{f}=749251$.
-   The distribution functions $F_{m}$ and $F_{f}$ are assumed to be absolutely continuous.
-   The test is a level $\alpha=0.05$ both sided test.

The null hypothesis $H_{0}$ is that the two distribution functions $F_{m}$ and $F_{f}$ are same. While, the alternative hypothesis is they are not equal. $$H_{0} : F_{f}= F_{m}\text{  } \text{  } \text{ against } \text{  } \text{  } H_{a} : F_{f} \neq F_{m} $$

The Kolmogorov-Smirnov test statistic can be defined as, $$
D_{m,f} = \max_x |S_{n_{f}}(x) - S_{{n_{m}}}(x)|
$$

-   $S_{n_{m}}(x)$ and $S_{n_{f}}(f)$ are respectively the empirical distribution function of male and female age sample.

-   [Rejection Criteria]{.underline}: If the p-value is less than $\alpha = 0.5$, we reject $H_{0}$.

\newpage

[\textbf{Findings}]{.underline}: Here it is evident that the p-value is very high. At 5% (or even higher) level of significance $H_{0}$ cannot be rejected as $p > 0.05$. It is safe to conclude that the gender-wise age of cancer patients have same distribution.

```{r}
#| echo: false
#| warning: false
ks.test(m, f, alternative = "two.sided")
```

-   In the analyzed age group, our findings reveal a notable trend in cancer prevalence, with breast cancer and cervix cancer exhibiting higher incidence rates among females compared to males. This observation suggests that these types of cancer disproportionately affect females within this age range .

-   Furthermore, our analysis indicates a notable increase in the number of patients diagnosed with these cancers, underscoring their dominant presence in the realm of cancer analysis.

```{r}
#| echo: false
#| fig-height: 4.5
#| fig-align: center
#| fig-cap: Plot of Empirical CDF's
plot <- plot(sorted_vals_m, ecdf_m, type = "s", 
             main = "Empirical CDF's", xlab = "Ages of male and female cancer patients", 
             ylab = "Cumulative Probability")
lines(sorted_vals_f, ecdf_f, type = "s", col = "pink")
legend("topleft", legend = c("Empirical CDF males", "Empirical CDF females"), 
       lty = 1, col = c("black", "pink"))
```

\newpage

## Conclusion

In brief, our analysis of cancer incidence in India reveals significant findings. Uttar Pradesh emerged as a high-risk region and the noticeable increase in cancer cases across India in recent times needs further investigation and intervention. Interestingly, our examination of the male-female age-wise distribution of cancer patients indicated a similarity with a negative skewness, suggesting a common trend in cancer occurrence across genders and age groups. Through exploratory data analysis (EDA), we gained insights into the structure and content of the datasets, ensuring data quality through categorical variable conversion, data merging and data quality checks.

Furthermore, our exploration of different cancer types demonstrated non-uniform distribution, with varying percentages of occurrence across the different types. We observed that Breast Cancer (BRCA) contained the most data points, almost $38\%$ of the entire dataset. To delve deeper into the factors influencing cancer types, we employed the multinomial logistic regression model, inputing gene expression values of various genes --- particularly those capturing maximum variability identified through Principal Component Analysis (PCA).

We performed parametric tests to assess differences in mean gene expression levels among cancer types. Rejection of the null hypothesis for certain genes in these tests signified the likeliness of significant differences for which further data analysis is required. Additionally, the one-vs-all t-test allowed us to compare specific cancer groups against the rest, contributing to a better understanding of inter-grouped differences. From the help of Non-Parametric tests, we concluded that from the age-wise cancer patients' data, the data were not normally distributed. Whereas for the `ICMR.Rdata` case, we found that out of $20$K+ genes, only about $17$K+ genes were following the normality criterion. If they were normally distributed, then we could have had further statistical inferences.

## Acknowledgement

We express our sincere gratitude to Prof. Subhajit Dutta for his continuous supervision and invaluable support throughout the completion of this project. His guidance, insights and encouragement have been fundamental in shaping our trajectory. We had the privilege of applying the knowledge and skills gained under his course, `MTH209: Data Science Lab - II` to tackle a real-world problem. This opportunity allowed us to delve deep into the subject matter and hone our abilities through practical applications.

We also extend our heartfelt thanks to our Teaching Assistants, Mr. Arghya Mukherjee and Ms. Annesha Deb for their assistance in guiding us through the process of selecting the project topic and steering us in the right direction. Amidst the initial confusion about choosing a topic, their wisdom helped us align our mutual interests to meet our goals. We are grateful for the unwavering support and encouragement from both of them which played a monumental role in the successful completion of this project.

\newpage

## Appendix

### Testing of Significance of the Regression coefficients in the Multinomial Logistic Regression

```{=tex}
\underline{\textbf{Model:}} Here our model is $E(Y_j) = \frac{e^{\boldsymbol{X^T_j\beta_i}}}{1+e^{\boldsymbol{X^T_j\beta_i}}}$, $j=1,2,...,n$\\[10pt]
\underline{\textbf{Assumptions:}} The error term $\epsilon_j$ is such that $E(\epsilon_j) = 0$ and $Var(\epsilon_j) = \sigma^2_j$ where $Var(Y_j) = \sigma^2_j$ and $\epsilon_j$'s are independently distributed, $j=1,2,...,n$\\[10pt]
\underline{\textbf{Hypothesis :}} $H_{0i} : \beta_i = 0$ vs $H_{1i} : \beta_i \neq 0$, $i=1,2,...,k$\\[10pt]
\underline{\textbf{Test statistic:}} Here our test statistic is $$T_i = \sqrt{k}\frac{\hat{\beta_i}}{\text{standard error}} \overset{a}{\sim} N(0,1)$$\\ [-36pt] {\scriptsize{$$\hspace{25mm}H_0$$}}\\ [-15pt]
where $\hat{\beta_i}$ is the Maximum Likelihood Estimator of $\beta_i$ \\
\underline{\textbf{Test Rule:}} We reject $H_{0i}$ at level $\alpha$ iff $p-value = P(|T_i| \geq observed(|T_i|)) \leq \alpha$ ; $i=1,2,...,k$ \\
```
### Shapiro-Wilk Normality Test

Shapiro and Wilk ($1965$) test was originally restricted for sample size of less than $50$. This test was the first test that was able to detect departures from normality due to either skewness and kurtosis, or both. It has become the preferred test because of its good power properties.

-   [Model]{.underline}: $X_1, X_2,...,X_n\overset{iid}{\sim}F(x)$

-   [Assumption]{.underline}: $F$ is absolutely continuous.

-   [Hypothesis]{.underline}: The null hypothesis $H_0$ assumes the random samples comes from a normal population with distribution function $\Phi$, while the alternative says that it does not come from $\Phi$. $$H_0 : F=\Phi \text{ against } H_a : F\neq \Phi$$

-   [Test Statistics]{.underline}: The required test statistic $W \in [0,1]$ $$
    W = \frac{(\sum_{i=1}^n a_{i}X_{(i)})^2}{(\sum_{i=1}^n (X_{i}-\bar{X})^2)} \text{        where    } a_{i} = (a_{1}, a_{2}, ...a_{n}) = \frac{m^TV^{-1}}{(m^TV^{-1}V^{-1}m)^{1/2}} 
    $$

    -   $X_{(i)}$ \text{and} $\bar{X}$ are the $i^{th}$ order statistics and the sample mean respectively.
    -   $m=(m_{1}, m_{2}, ...m_{n})^{1/2}$ are the expected values of the order statistics of independent and identically distributed random variables sampled from the standard normal distribution.
    -   $V$ is the covariance matrix of those order statistics.

-   [Rejection Criteria]{.underline}: If the p-value is smaller than a pre-determined significance level $\alpha$, we reject $H_{0}$.

### Empirical Distribution Function (EDF)

For a random sample from the distribution $F_{X}$, the empirical distribution function or edf, denoted by $S_{n}(x)$, is simply the proportion of sample values less than or equal to the specified value $x$, that is,

$$S_{n}(x)=\frac{\text{number of sample values} \leq x}{n}$$ Suppose that the $n$ sample observations are distinct and arranged in increasing order so that $X_{(1)}$ is the smallest, $X_{(2)}$ is the second smallest, . . . , and $X_{(n)}$ is the largest. Then, a formal definition of the edf $S_{n}(x)$ is $$
S_n(x) = 
\begin{cases}
    0 & \text{if } x < X_{(1)} \\ 
    \frac{i}{n} & \text{if } X_{(i)} \leq x < X_{(i+1)} \text{ for } \text{  } i = 1, 2, \ldots, n \\
    0 & \text{if } x \geq X_{(n)}
\end{cases}
$$

### The Kolmogorov-Smirnov One Sample Test

```{=tex}
\textbf{Model :} $X_1, X_2,...,X_n\overset{iid}{\sim}F(x)$\\ 
\textbf{Assumption :} Here we assume the F is absolutely continuous distribution function.\\ \textbf{Hypothesis :} Here we are interested in testing whether the random sample come from a known distribution with distribution function $F_0(x)$ (say). That is,\\ [-10pt] $$H_0 : F=F_0 \text{ against } H_a : F\neq F_0$$\\[-15pt] where $F=F_0\equiv F(x)=F_0(x)$ $\forall$ $x$\\ and $F=F_0\equiv F(x)\neq F_0(x) \text{ with strict inequality for atleast one } x$\\ Here we are mainly interested in checking Normality. So, $F_0(x)=\Phi(x)$\\ So, the hypothesis becomes,\\ [-10pt] $$H_0 : F=\Phi \text{ against } H_a : F\neq \Phi$$\\[-15pt] where $\Phi$ is the cumulative distribution function of standard normal distribution.\\ \textbf{Test Statistic :} For testing $H_0$ against $H_a$ we define the following statistic,\\ $$D_n = \sup_{x\in \mathbb{R}}\left|\widehat{F_n(x)}-\Phi(x)\right|$$\\ [-10pt] Notice that $\widehat{F_n(x)}$ approximate the true distribution function $\Phi$ . $\widehat{F_n(x)}$ by definition is a step function i.e. the absolute difference measured by $D_n$ provide us the departure of the true situation from the null hypothesis towards the corresponding alternative.\\ The distribution of the test statistics is free from the population distribution, \\ \textbf{Distribution Free :}\\ \textcolor{violet}{Exact Distribution Free (EDF) of $D_n$ :} Here we use the ordered statistics,\\ [-10pt] $$X_{(1)}, X_{(2)}, ... , X_{(n)}, \text{ Further we denote } X_{(0)}=-\infty \text{ and } X_{(n+1)}=\infty$$\\ [-45pt]

\begin{align*}
D_n &= \sup_{x\in \mathbb{R}}\left|\widehat{F_n(x)}-\Phi(x)\right| \\
&= \max_{i=0,1,2,...,n}\left\{\sup_{X_{(i)}\le x\le X_{(i+1)}}\left|\widehat{F_n(x)}-\Phi(x)\right|\right\}\\
&= \max\left\{o, \max_{i=1,2,...,n}\left\{\sup_{X_{(i)}\le x\le X_{(i+1)}}\left|\widehat{F_n(x)}-\Phi(x)\right|\right\}\right\}&\\
&= \max\left\{o, \max_{i=1,2,...,n}\left\{\sup_{X_{(i)}\le x\le X_{(i+1)}}\left|\frac{i}{n}-\Phi(x)\right|\right\}\right\} \hspace{30pt} \left[\because \widehat{F_n(x)}=\frac{i}{n}\right]\\
&= \max\left\{o, \max_{i=1,2,...,n}\left\{\left|\frac{i}{n}-\Phi(x_{(i)})\right|\right\}\right\}\\
\end{align*}\\ [-21pt]
Notice that,\\ [-15pt]
$$X_1, X_2,...,X_n\overset{iid}{\sim}\Phi$$\\ [-30pt] {\scriptsize{$$\hspace{19mm}H_0$$}}\\ [-20.5pt] $$\implies U_i=\Phi(X_i)\overset{iid}{\sim}U(0,1)$$\\ [-30pt] {\scriptsize{$$\hspace{15.5mm}H_0$$}}\\ [-20.5pt] Since $\Phi$ is absolutely continuous, we can conclude that,\\ [-8pt] $$\implies U_{(i)}=\Phi\left(X_{(i)}\right)\overset{iid}{\sim}U(0,1)$$\\ [-30pt] {\scriptsize{$$\hspace{21mm}H_0$$}}\\ [-13pt] That is $D_n$ (under $H_0$) depends on the ordered statistics $\left(U_{(1)}, U_{(2)},..., U_{(n)}\right)$ from U(0,1). Hence the test is based on $D_n$ is EDF (Exact Distribution Free).\\ \textbf{Test :} Notice that $D_n$ depends on the empirical distribution function $\widehat{F_n(x)}$ which represents the true distribution function. Thus the directional difference measured by $D_n$ actually indicate the departure of the true situation form the null hypothesis towards the alternative $H_a$ i.e. under $H_a : F\neq F_0$ becomes larger than that under $H_0$. On the other hand a small value of $D_n$ indicates the acceptance of $H_0$. Thus a right tail test based on $D_n$ will be appropriate for testing $H_0 : F=\Phi \text{ against } H_a : F\neq \Phi$.\\ We reject $H_0 : F=\Phi \text{ against } H_a : F\neq \Phi$ at level $\alpha$ if,\\ [-10pt] $$D_n > d_\alpha$$\\ [-15pt] In terms of p-value we can say, we reject $H_0 : F=\Phi \text{ against } H_a : F\neq \Phi$ at level $\alpha$ if,\\ [-8pt] $$p-value=P_{H_{0}}\left(D_n\ge observed(D_n)\right)\le \alpha$$\\
```
\newpage

### The Kolmogorov-Smirnov Two Sample Test

Two sample KS test is a non-parametric test which is used to compare two different samples are coming from the same population or not.

The order statistics corresponding to two random samples of size $m$ and $n$ from continuous populations $F_{X}$ and $F_{Y}$, are

$$X_{(1)}, X_{(2)},...,X_{(m)} \text{   and    } \text{  } Y_{(1)}, Y_{(2)},...,Y_{(n)}$$

Their respective empirical distribution functions, denoted by $S_{m}(x)$ and $S_{n}(x)$, are defined as:

$$
S_m(x) = 
\begin{cases}
    0 & \text{if } x < X_{(1)} \\ 
    \frac{k}{m} & \text{if } X_{(k)} \leq x < X_{(k+1)} \text{ for } \text{  } k = 1, 2, \ldots, m-1 \\
    0 & \text{if } x \geq X_{(m)}
\end{cases}
$$

and

$$
S_n(x) = 
\begin{cases}
    0 & \text{if } x < Y_{(1)} \\ 
    \frac{k}{n} & \text{if } Y_{(k)} \leq x < Y_{(k+1)} \text{ for } \text{  } k = 1, 2, \ldots, n-1 \\
    0 & \text{if } x \geq Y_{(n)}
\end{cases}
$$ In a combined ordered arrangement of $m+n$ sample observations, $S_m(x)$ and $S_n(x)$ are the respective proportions of $X$ and $Y$ observations which do not exceed the specified value $x$.

If the null hypothesis

$$
H_0: F_Y(x) = F_X(x)  \text{  } \text{ } \forall{x}
$$

is true, the population distributions are identical and we have two samples from the same population. The empirical distribution functions for the $X$ and $Y$ samples are reasonable estimates of their respective population cdf. Therefore, allowing for sampling variation, there should be reasonable agreement between the two empirical distributions if indeed $H_0$ is true; otherwise the data suggest that $H_0$ is not true and therefore should be rejected. In other words, how close do the two empirical cdf's have to be so that they could be viewed as not significantly different, taking account of the sampling variability. This approach necessarily requires a definition of closeness. The two-sided Kolmogorov-Smirnov two-sample test criterion, denoted by $D_{m,n}$, is based on the maximum absolute difference between the two empirical distributions.

$$
D_{m,n} = \max_x |S_{m}(x) - S_{n}(x)| 
$$ \newpage Since here only the magnitudes, and not the directions, of the deviations are considered, $D_{m,n}$ is appropriate for a general two-sided alternative

$$
H_A: F_Y(x) \neq F_X(x) \text{ for some } x.
$$

and the rejection region is in the upper tail, defined by

$$
D_{m,n} \geq c_{\alpha}
$$ where

$$
P(D_{m,n} \geq c_{\alpha} \,|\, H_0) \leq \alpha
$$ Because of the Glivenko-Cantelli theorem, the test is consistent for this alternative. The p-value is

$$
p = P(D_{m,n} \geq D_{observed} \,|\, H_0)
$$

## References

-   Fundamentals of Statistics (*Volume One*); A.M. Gun, M.K. Gupta, B. Dasgupta; The World Press Pvt. Ltd., $2019$.

-   The Cancer Breakthrough: A Nutritional Handbook for Doctors and Patients (*Paperback*) -- $29$ July, $2007$.

-   Razali, N. and Wah, Y. ($2011$) Power Comparisons of Shapiro-Wilk, Kolmogorov-Smirnov, Lilliefors and Anderson-Darling tests. Journal of Statistical Modeling and Analytics, $2$, $21$-$33$.

-   Wilk, W. ($2015$) Shapiro Wilk And Related Tests For Normality, Massachusetts Insitute of Technology.

-   Gibbons, J.D. and Chakraborti, S. ($2014$), Nonparametric Statistical Inference, Fourth Edition: Revised and Expanded.
